{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sweet Dreams, Martian\n",
    "![Mars DeepDream Demonstration](https://raw.githubusercontent.com/arjun-krishna1/dreaming-of-mars-gifs/main/mars-deep-dream-imagenet1.gif)\n",
    "### When the first human drifts to sleep on Mars,\n",
    "### Looking out into the harsh Martian desert,\n",
    "### What will they see in their dreams?\n",
    "- Creating DeepDream sequences using Mars landscape images from the Curiosity Rover\n",
    "- Code adapted from [Tensorflow DeepDream Tutorial](https://www.tensorflow.org/tutorials/generative/deepdream)\n",
    "- [See on Github](https://github.com/arjun-krishna1/dreaming-of-mars/blob/deep-dream/DeepDream.ipynb)\n",
    "- [See on nbviewer(in case GitHub is not rendering)](https://nbviewer.jupyter.org/github/arjun-krishna1/sweet-dreams-martian/blob/main/DeepDream.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T17:54:26.279226Z",
     "iopub.status.busy": "2021-06-16T17:54:26.278648Z",
     "iopub.status.idle": "2021-06-16T17:54:26.304955Z",
     "shell.execute_reply": "2021-06-16T17:54:26.305292Z"
    },
    "id": "g_Qp173_NbG5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import PIL.Image\n",
    "\n",
    "from random import randint\n",
    "from time import strftime, gmtime\n",
    "\n",
    "import IPython.display as display\n",
    "\n",
    "import cv2 as cv\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Image From NASA Mars Images API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T17:54:26.308772Z",
     "iopub.status.busy": "2021-06-16T17:54:26.308249Z",
     "iopub.status.idle": "2021-06-16T17:54:26.310192Z",
     "shell.execute_reply": "2021-06-16T17:54:26.309782Z"
    },
    "id": "0lclzk9sNbG2"
   },
   "outputs": [],
   "source": [
    "url = 'https://mars.nasa.gov/msl-raw-images/msss/01590/mcam/1590MR0081020030800438E01_DXXX.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Download an image and read it into a NumPy array.\n",
    "def download(url, max_dim=None):\n",
    "  name = url.split('/')[-1]\n",
    "  image_path = tf.keras.utils.get_file(name, origin=url)\n",
    "  img = PIL.Image.open(image_path)\n",
    "  if max_dim:\n",
    "    img.thumbnail((max_dim, max_dim))\n",
    "  return np.array(img)\n",
    "\n",
    "# Turn a normalized image array back into an image\n",
    "def deprocess(img):\n",
    "  img = 255*(img + 1.0)/2.0\n",
    "  return tf.cast(img, tf.uint8)\n",
    "\n",
    "def get_save_name(buffer=\"start\"):\n",
    "    name = buffer + strftime(\"%X\", gmtime())\n",
    "    name += str(randint(0, 1000)) + \".png\"\n",
    "    return name\n",
    "\n",
    "\n",
    "# Downsizing the image makes it easier to work with.\n",
    "original_img = download(url, 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T17:54:26.446135Z",
     "iopub.status.busy": "2021-06-16T17:54:26.442954Z",
     "iopub.status.idle": "2021-06-16T17:54:34.274868Z",
     "shell.execute_reply": "2021-06-16T17:54:34.275269Z"
    },
    "id": "GlLi48GKNbGy"
   },
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.InceptionV3(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T17:54:34.281544Z",
     "iopub.status.busy": "2021-06-16T17:54:34.280920Z",
     "iopub.status.idle": "2021-06-16T17:54:34.289039Z",
     "shell.execute_reply": "2021-06-16T17:54:34.288614Z"
    },
    "id": "08KB502ONbGt"
   },
   "outputs": [],
   "source": [
    "# Maximize the activations of these layers\n",
    "names = ['mixed1', 'mixed3']\n",
    "layers = [base_model.get_layer(name).output for name in names]\n",
    "\n",
    "# Create the feature extraction model\n",
    "dream_model = tf.keras.Model(inputs=base_model.input, outputs=layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T17:54:34.293717Z",
     "iopub.status.busy": "2021-06-16T17:54:34.293014Z",
     "iopub.status.idle": "2021-06-16T17:54:34.295017Z",
     "shell.execute_reply": "2021-06-16T17:54:34.295357Z"
    },
    "id": "8MhfSweXXiuq"
   },
   "outputs": [],
   "source": [
    "def calc_loss(img, model):\n",
    "  # Pass forward the image through the model to retrieve the activations.\n",
    "  # Converts the image into a batch of size 1.\n",
    "  img_batch = tf.expand_dims(img, axis=0)\n",
    "  layer_activations = model(img_batch)\n",
    "  if len(layer_activations) == 1:\n",
    "    layer_activations = [layer_activations]\n",
    "\n",
    "  losses = []\n",
    "  for act in layer_activations:\n",
    "    loss = tf.math.reduce_mean(act)\n",
    "    losses.append(loss)\n",
    "\n",
    "  return  tf.reduce_sum(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T17:54:46.662520Z",
     "iopub.status.busy": "2021-06-16T17:54:46.661954Z",
     "iopub.status.idle": "2021-06-16T17:54:46.663591Z",
     "shell.execute_reply": "2021-06-16T17:54:46.663930Z"
    },
    "id": "oGgLHk7o80ac"
   },
   "outputs": [],
   "source": [
    "def random_roll(img, maxroll):\n",
    "  # Randomly shift the image to avoid tiled boundaries.\n",
    "  shift = tf.random.uniform(shape=[2], minval=-maxroll, maxval=maxroll, dtype=tf.int32)\n",
    "  img_rolled = tf.roll(img, shift=shift, axis=[0,1])\n",
    "  return shift, img_rolled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T17:54:46.667381Z",
     "iopub.status.busy": "2021-06-16T17:54:46.666767Z",
     "iopub.status.idle": "2021-06-16T17:54:46.743890Z",
     "shell.execute_reply": "2021-06-16T17:54:46.744245Z"
    },
    "id": "sKsiqWfA9H41"
   },
   "outputs": [],
   "source": [
    "shift, img_rolled = random_roll(np.array(original_img), 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tGIjA3UhhAt8"
   },
   "source": [
    "Here is a tiled equivalent of the `deepdream` function defined earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T17:54:46.751930Z",
     "iopub.status.busy": "2021-06-16T17:54:46.751345Z",
     "iopub.status.idle": "2021-06-16T17:54:46.753291Z",
     "shell.execute_reply": "2021-06-16T17:54:46.752809Z"
    },
    "id": "x__TZ0uqNbGm"
   },
   "outputs": [],
   "source": [
    "class TiledGradients(tf.Module):\n",
    "  def __init__(self, model):\n",
    "    self.model = model\n",
    "\n",
    "  @tf.function(\n",
    "      input_signature=(\n",
    "        tf.TensorSpec(shape=[None,None,3], dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=[], dtype=tf.int32),)\n",
    "  )\n",
    "  def __call__(self, img, tile_size=512):\n",
    "    shift, img_rolled = random_roll(img, tile_size)\n",
    "\n",
    "    # Initialize the image gradients to zero.\n",
    "    gradients = tf.zeros_like(img_rolled)\n",
    "    \n",
    "    # Skip the last tile, unless there's only one tile.\n",
    "    xs = tf.range(0, img_rolled.shape[0], tile_size)[:-1]\n",
    "    if not tf.cast(len(xs), bool):\n",
    "      xs = tf.constant([0])\n",
    "    ys = tf.range(0, img_rolled.shape[1], tile_size)[:-1]\n",
    "    if not tf.cast(len(ys), bool):\n",
    "      ys = tf.constant([0])\n",
    "\n",
    "    for x in xs:\n",
    "      for y in ys:\n",
    "        # Calculate the gradients for this tile.\n",
    "        with tf.GradientTape() as tape:\n",
    "          # This needs gradients relative to `img_rolled`.\n",
    "          # `GradientTape` only watches `tf.Variable`s by default.\n",
    "          tape.watch(img_rolled)\n",
    "\n",
    "          # Extract a tile out of the image.\n",
    "          img_tile = img_rolled[x:x+tile_size, y:y+tile_size]\n",
    "          loss = calc_loss(img_tile, self.model)\n",
    "\n",
    "        # Update the image gradients for this tile.\n",
    "        gradients = gradients + tape.gradient(loss, img_rolled)\n",
    "\n",
    "    # Undo the random shift applied to the image and its gradients.\n",
    "    gradients = tf.roll(gradients, shift=-shift, axis=[0,1])\n",
    "\n",
    "    # Normalize the gradients.\n",
    "    gradients /= tf.math.reduce_std(gradients) + 1e-8 \n",
    "\n",
    "    return gradients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T17:54:46.756605Z",
     "iopub.status.busy": "2021-06-16T17:54:46.756020Z",
     "iopub.status.idle": "2021-06-16T17:54:46.758246Z",
     "shell.execute_reply": "2021-06-16T17:54:46.757853Z"
    },
    "id": "Vcq4GubA2e5J"
   },
   "outputs": [],
   "source": [
    "get_tiled_gradients = TiledGradients(dream_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T17:54:46.764236Z",
     "iopub.status.busy": "2021-06-16T17:54:46.763656Z",
     "iopub.status.idle": "2021-06-16T17:54:46.765927Z",
     "shell.execute_reply": "2021-06-16T17:54:46.765509Z"
    },
    "id": "gA-15DM4NbGk"
   },
   "outputs": [],
   "source": [
    "def run_deep_dream_with_octaves(img, steps_per_octave=100, step_size=0.01, \n",
    "                                octaves=range(-2,3), octave_scale=1.3):\n",
    "  dream = []\n",
    "  base_shape = tf.shape(img)\n",
    "  img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "  img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
    "\n",
    "  initial_shape = img.shape[:-1]\n",
    "  img = tf.image.resize(img, initial_shape)\n",
    "  for octave in octaves:\n",
    "    # Scale the image based on the octave\n",
    "    new_size = tf.cast(tf.convert_to_tensor(base_shape[:-1]), tf.float32)*(octave_scale**octave)\n",
    "    img = tf.image.resize(img, tf.cast(new_size, tf.int32))\n",
    "\n",
    "    for step in range(steps_per_octave):\n",
    "      gradients = get_tiled_gradients(img)\n",
    "      img = img + gradients*step_size\n",
    "      img = tf.clip_by_value(img, -1, 1)\n",
    "\n",
    "      if step % 3 == 0:        \n",
    "        display.clear_output(wait=True)\n",
    "        dream.append(deprocess(img))\n",
    "        print(len(dream))\n",
    "    \n",
    "  return dream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170\n"
     ]
    }
   ],
   "source": [
    "dream_frames = run_deep_dream_with_octaves(img=original_img, step_size=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Video From Dream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame_for_video(frame, text=\"\", size=(400, 400)):\n",
    "    frame = cv.resize(np.array(frame), size)\n",
    "    frame = cv.cvtColor( frame, cv.COLOR_RGB2BGR )\n",
    "    if len(text) > 0:\n",
    "        text_bottom_left = (int(size[0]/5), int(size[0]/2))\n",
    "        cv.putText( frame, text, text_bottom_left, cv.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 3)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourcc = cv.VideoWriter_fourcc(*'XVID')\n",
    "out = cv.VideoWriter(\"mars_dream.mp4\", fourcc, 4.0, (400, 400))\n",
    "\n",
    "for i in range(6):\n",
    "    out.write(process_frame_for_video(dream_frames[0], text=\"Sweet Dreams,\",))\n",
    "    \n",
    "for i in range(6):\n",
    "    out.write(process_frame_for_video(history[0], text=\"Martian\"))\n",
    "    \n",
    "for i in range(6):\n",
    "    out.write(process_frame_for_video(history[0], text=\"By Arjun Krishna\"))\n",
    "\n",
    "for i in range(len(history)):\n",
    "    out.write(process_frame_for_video(history[i]))\n",
    "    \n",
    "out.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "deepdream.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
